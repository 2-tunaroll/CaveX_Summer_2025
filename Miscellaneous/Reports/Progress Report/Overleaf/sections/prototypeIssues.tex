\section{Identified Prototype Issues}
\label{sec:prototype-issues}
The issues or areas for improvement with the current prototype are discussed in this section and form the basis for the project's technical objectives.

\subsection{Mapping \& Localisation}
In the context of autonomy, mapping is where the robot has an understanding of the environment within which it resides and localisation is the state wherein a robot knows its location with respect to this environment. The current prototype collects map data using its LiDAR sensor but does not construct a map in real time and has no localisation capability. These functions underpin further autonomous abilities and, thus, the current prototype does not posses the ability to demonstrate autonomous behaviour.

\subsection{Autonomous Navigation}
The robot is currently manually controlled which limits its utility and ability to satisfy the system requirements. Autonomous navigation is the key objective of this year's iteration. As identified by the literature review in Section \ref{sec:litreview}, the robot contains a LiDAR scanner which presents the possibility to implement a real time LiDAR-based SLAM algorithm. This functionality is yet to be implemented on the current prototype.

\subsubsection{Obstacle Detection \& Avoidance}
The robot currently has a peripheral infrared (IR) sensor for detecting sharp extrusions on the caves ceiling, known as Stalactites (NPS 2015). This information is sent to a connected laptop so that the operator can adjust the robot's position accordingly. However, no autonomous function exists for the robot to adjust its path based on the data from the IR sensors. Autonomous obstacle detection and avoidance is most beneficial as it would allow for the robot to adjust its own path without the need for user intervention. This extends the mission capability of the robot, allowing it to venture into cave sections beyond what the user can observe directly. The data from the LiDAR sensor can also be used in conjunction with the IR sensor to achieve this capability. Other obstacles including rocks and sharp ascents or descents can also be detected with this method such that the robot can autonomously alter its gait accordingly. Another key limitation of the current prototype is its ability to maintain stability when a sharp descent or hole in the ground is encountered. Obstacles of this nature must also be detected to allow the robot to adjust its gait for stable and efficient traversal.

\subsubsection{Pathfinding}
Due to the lack of mapping and localisation the prototype has no ability to plan a path through the map of the cave environment. The robot must also have an ability to recognise sections of the cave which have already been explored in the map it is producing. This will ensure that the robot is producing a complete map of the area.

\subsection{Dynamic Gait Optimisation}
The current prototype is equipped with three different walking gaits. Each gait has different characteristics such as power consumption, movement speed, and stability. As a result, certain gaits are better suited for different terrains (Bright et al. 2022). Additionally, incline and decline considerations further complicate the system's dynamics. Currently, the gaits are selected manually using a controller and there is no closed-loop feedback system to monitor its performance with a particular gait. The robot is, therefore, limited in the terrains it can traverse. During the preliminary testing of the robot, highlighted in Section \ref{sec:prototype-performance}, it was also observed that the robot legs were slipping along the acrylic sheet used on the incline testing rig. This significantly reduced the robot's stability and movement across the rig's surface. As the robot's intended operating environment is a cave, it is expected that some surfaces the robot must traverse will be characterised by limited friction and, therefore, a risk of slipping. A gait optimisation algorithm which dynamically responds to surface characteristics is liable to improve the robot's ability to traverse sub-optimal terrains.


\subsection{Computational Power}
The current onboard processor for the robot is the NVIDIA Jetson Nano. This processor is more powerful and AI-capable than the secondary Arduino Uno processor. The robot aims to use large data streams from the LiDAR scanner to conduct SLAM in real time. This means that the number of floating point operations per second (FLOPS) is a key parameter for performance. An uncertainty exists whether the Jetson Nano will have sufficient computational power to conduct the SLAM algorithms required for autonomous navigation. Potential processing power upgrades include the Jetson Orin Nano 8GB, Jetson Orin NX 8GB, or Jetson Orin NX 16GB.

\subsection{Development \& Debugging} % lack of a wireless communication system (like DroneDeploy) makes it hard to efficiently develop and debug the robot and its software
\label{sec:dev-debug}
Deploying software onto the robot in its current state is an inefficient and convoluted process. To access the graphical user interface (GUI) of the Ubuntu operating system installed on the Jetson processor, the Jetson must be connected to a monitor. Once this connection is made software can be pulled from the relevant repository and built on the robot. This means that small changes in software cannot be deployed onto the robot in quick succession which limits the development process' efficiency. A possible objective to improve this process is to utilise a build software on the Jetson that facilitates continuous integration (CI) and deployment (CD) from software located on a repository with the code base stored on the machine. This will allow for changes in the code on the repository to be incorporated onto the robot without the need to manually pull and build the new code. Debugging code deployed on the robot is also a significant challenge due to the lack of a wireless communication system. One particular communication system that could be utilised is the DroneDeploy software which can facilitate data communication between the robot and a connected device over a network. This software can facilitate a visualisation of real time mapping, related to OB5, which allows bugs in software to be identified by the quality of the map produced. Having such a software will greatly speed up the debugging process rather than having to post process the LiDAR data after each run to inspect map quality.

\subsection{Summary}
The prototype issues mentioned in this section present key opportunities to improve the functionality of the robot. These limitations form the basis of the majority of this iteration's technical objectives. Improving the development and debugging process is not a technical objective of the project but will allow for a streamlined software development process to occur and will benefit future project iterations significantly.